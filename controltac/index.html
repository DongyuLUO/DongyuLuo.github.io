<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image">
  <meta name="keywords" content="ControlTac, tactile, generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image</title>

  <!-- Preconnect for better performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  
  <link rel="icon" type="image/svg+xml" href="./static/images/favicon.svg">
  <link rel="icon" type="image/x-icon" href="./static/images/favicon.ico">
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <style>
    :root {
      --primary-blue: #2563eb;
      --accent-blue: #3b82f6;
      --light-blue: #dbeafe;
      --dark-blue: #1e40af;
      --gradient-start: #667eea;
      --gradient-end: #764ba2;
      --text-primary: #1f2937;
      --text-secondary: #6b7280;
      --border-color: #e5e7eb;
      --shadow-soft: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
      --shadow-medium: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
    }

    * {
      scroll-behavior: smooth;
    }

    body {
      font-family: 'Inter', sans-serif;
      line-height: 1.6;
      color: var(--text-primary);
      background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
    }

    /* Enhanced navbar with modern styling */
    .navbar {
      background: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(20px);
      border-bottom: 1px solid var(--border-color);
      position: sticky;
      top: 0;
      z-index: 1000;
      transition: all 0.3s ease;
    }

    .navbar-brand {
      padding: 0 1rem;
    }

    .navbar-item {
      font-weight: 500;
      transition: all 0.3s ease;
    }

    .navbar-item:hover {
      background: var(--light-blue);
      color: var(--primary-blue);
    }

    /* Hero section with GIF background */
    .hero-section {
      position: relative;
      color: white;
      padding: 3rem 0 2rem;
      overflow: hidden;
      min-height: 70vh;
      display: flex;
      align-items: center;
      background-image: url('./static/images/front.gif');
      background-size: cover;
      background-position: center;
      background-repeat: no-repeat;
    }

    .hero-section::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: linear-gradient(135deg, rgba(0, 0, 0, 0.4) 0%, rgba(0, 0, 0, 0.6) 100%);
      z-index: 1;
    }

    .hero-section::after {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="grain" width="100" height="100" patternUnits="userSpaceOnUse"><circle cx="25" cy="25" r="1" fill="white" opacity="0.1"/><circle cx="75" cy="75" r="1" fill="white" opacity="0.1"/><circle cx="50" cy="10" r="0.5" fill="white" opacity="0.15"/><circle cx="10" cy="60" r="0.5" fill="white" opacity="0.15"/><circle cx="90" cy="40" r="0.5" fill="white" opacity="0.15"/></pattern></defs><rect width="100" height="100" fill="url(%23grain)"/></svg>');
      z-index: 2;
      pointer-events: none;
    }

    .hero-content {
      position: relative;
      z-index: 3;
      max-width: 800px;
      margin: 0 auto;
      padding: 0 2rem;
    }

    .publication-title {
      font-weight: 700;
      font-size: 2.5rem;
      line-height: 1.2;
      margin-bottom: 2rem;
      text-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
    }

    .name {
      background: linear-gradient(45deg, #fbbf24, #f59e0b);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      font-weight: 800;
      text-shadow: none;
      font-variant: small-caps;
    }

    .author-block a {
      color: rgba(255, 255, 255, 0.9);
      text-decoration: none;
      transition: all 0.3s ease;
      text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }

    .author-block a:hover {
      color: white;
      text-shadow: 0 0 8px rgba(255, 255, 255, 0.5);
    }

    .publication-authors {
      text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }

    /* Video section with enhanced styling - narrower */
    .video-hero {
      background: white;
      padding: 3rem 0;
      position: relative;
    }

    .video-hero::after {
      content: '';
      position: absolute;
      bottom: 0;
      left: 0;
      right: 0;
      height: 1px;
      background: linear-gradient(90deg, transparent, var(--border-color), transparent);
    }

    .video-container {
      position: relative;
      width: 100%;
      max-width: 600px;
      margin: 0 auto;
      background: #000;
      border-radius: 16px;
      overflow: hidden;
      box-shadow: var(--shadow-medium);
      aspect-ratio: 16 / 9;
      transition: transform 0.3s ease, box-shadow 0.3s ease;
    }

    .video-container:hover {
      transform: translateY(-4px);
      box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
    }

    .video-container iframe {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      border: none;
      border-radius: 16px;
    }

    .video-description {
      max-width: 600px; 
      margin: 2rem auto 0;
      padding: 0 1rem;
      text-align: center;
      color: var(--text-secondary);
      font-size: 1.1rem;
      line-height: 1.7;
    }

    /* Teaser section with enhanced visual flow - narrower */
    .teaser-section {
      background: linear-gradient(135deg, #fafafa 0%, #ffffff 100%);
      padding: 4rem 0;
      position: relative;
    }

    .teaser-section::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 1px;
      background: linear-gradient(90deg, transparent, var(--border-color), transparent);
    }

    .teaser-content {
      display: flex;
      flex-direction: column;
      gap: 2rem;
      align-items: center;
      max-width: 700px; 
      margin: 0 auto;
      padding: 0 2rem;
    }

    .teaser-image {
      width: 100%;
      max-width: 700px; 
      border-radius: 20px;
      box-shadow: var(--shadow-medium);
      transition: transform 0.3s ease;
      display: block;
      margin: 0 auto;
    }

    .teaser-image:hover {
      transform: scale(1.02);
    }

    .teaser-description {
      background: white;
      padding: 2rem;
      border-radius: 16px;
      box-shadow: var(--shadow-soft);
      border: 1px solid var(--border-color);
      max-width: 650px; 
      text-align: left;
    }

    /* Button enhancements */
    .publication-links {
      display: flex;
      gap: 1rem;
      justify-content: center;
      flex-wrap: wrap;
      margin-top: 2rem;
    }

    .button.is-rounded {
      background: rgba(255, 255, 255, 0.2);
      border: 2px solid rgba(255, 255, 255, 0.3);
      color: white;
      font-weight: 500;
      transition: all 0.3s ease;
      backdrop-filter: blur(10px);
      text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
    }

    .button.is-rounded:hover {
      background: rgba(255, 255, 255, 0.3);
      border-color: rgba(255, 255, 255, 0.5);
      transform: translateY(-2px);
      box-shadow: 0 8px 15px rgba(0, 0, 0, 0.2);
    }

    .button:disabled {
      opacity: 0.6;
      cursor: not-allowed;
    }

    /* Section styling improvements */
    .content-section {
      background: white;
      margin: 2rem 0;
      border-radius: 16px;
      box-shadow: var(--shadow-soft);
      border: 1px solid var(--border-color);
    }

    .section-title {
      font-size: 2rem;
      font-weight: 700;
      color: var(--text-primary);
      margin-bottom: 1.5rem;
      position: relative;
    }

    .section-title::after {
      content: '';
      position: absolute;
      bottom: -8px;
      left: 50%;
      transform: translateX(-50%);
      width: 60px;
      height: 3px;
      background: linear-gradient(90deg, var(--gradient-start), var(--gradient-end));
      border-radius: 2px;
    }

    /* Enhanced responsive design */
    @media screen and (max-width: 768px) {
      .hero-section {
        padding: 2rem 0 1.5rem;
        min-height: 70vh;
      }

      .hero-content {
        padding: 0 1.5rem;
      }

      .publication-title {
        font-size: 1.8rem;
        margin-bottom: 1.5rem;
      }

      .video-hero {
        padding: 2rem 0;
      }

      .video-container {
        margin: 0 1rem;
        border-radius: 12px;
        max-width: calc(100% - 2rem);
      }

      .video-description {
        font-size: 1rem;
        margin-top: 1.5rem;
        max-width: calc(100% - 2rem);
      }

      .teaser-section {
        padding: 2rem 0;
      }

      .teaser-content {
        padding: 0 1.5rem;
        max-width: calc(100% - 3rem);
      }

      .teaser-description {
        margin: 0 0;
        padding: 1.5rem;
        max-width: 100%;
      }

      .publication-links {
        flex-direction: column;
        align-items: center;
        gap: 0.75rem;
      }

      .button.is-rounded {
        width: 200px;
      }

      .section-title {
        font-size: 1.5rem;
      }

      .content-wrapper {
        padding: 0 1.5rem;
      }
    }

    @media screen and (min-width: 769px) and (max-width: 1024px) {
      .teaser-content {
        max-width: 600px;
      }
      
      .teaser-image {
        max-width: 600px;
      }
      
      .video-container {
        max-width: 500px;
      }
      
      .video-description {
        max-width: 500px;
      }
    }

    @media screen and (min-width: 1025px) {
      .teaser-content {
        max-width: 700px;
      }
    }

    /* Enhanced image responsiveness and centering - narrower containers */
    .responsive-image {
      width: 100%;
      height: auto;
      display: block;
      border-radius: 12px;
      margin: 0 auto;
      max-width: 600px; 
    }

    /* Smooth animations */
    .fade-in {
      animation: fadeIn 0.8s ease-out;
    }

    @keyframes fadeIn {
      from {
        opacity: 0;
        transform: translateY(20px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    /* Content sections styling - narrower content */
    .abstract-section, .method-section, .visualization-section, .downstream-section {
      background: white;
      padding: 3rem 0;
      position: relative;
    }

    .abstract-section::before, .method-section::before, .visualization-section::before, .downstream-section::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 1px;
      background: linear-gradient(90deg, transparent, var(--border-color), transparent);
    }

    .content-wrapper {
      max-width: 800px; 
      margin: 0 auto;
      padding: 0 2rem;
    }

    /* Typography improvements */
    .content p {
      font-size: 1.1rem;
      line-height: 1.8;
      color: var(--text-primary);
      margin-bottom: 1.5rem;
      max-width: 700px;
      margin-left: auto;
      margin-right: auto;
    }

    .subtitle.is-5 {
      color: var(--primary-blue);
      font-weight: 600;
      margin-top: 3rem;
      margin-bottom: 1rem;
    }

    /* Enhanced GIF and image containers - narrower and centered */
    .gif-container, .image-container {
      text-align: center;
      margin: 2rem auto;
      display: flex;
      justify-content: center;
      align-items: center;
      max-width: 600px; 
    }

    .gif-container img, .image-container img {
      border-radius: 12px;
      box-shadow: var(--shadow-soft);
      transition: transform 0.3s ease;
      max-width: 100%;
      height: auto;
      display: block;
    }

    .gif-container img:hover, .image-container img:hover {
      transform: scale(1.02);
    }

  
    #BibTeX {
      background: #f8fafc;
      border-radius: 16px;
      margin: 2rem auto;
      padding: 2rem;
      max-width: 700px;
      text-align: left;
    }
    
    #BibTeX h2 {
      text-align: center;
    }
    
    #BibTeX pre {
      background: white;
      border: 1px solid var(--border-color, #e2e8f0);
      border-radius: 8px;
      padding: 1.2rem;
      font-family: 'JetBrains Mono', monospace;
      font-size: 0.8rem;
      overflow-x: auto;
      white-space: pre; 
      line-height: 1.6;
      color: #1e293b;
    }



    /* Footer styling */
    .footer {
      background: var(--text-primary);
      color: white;
      padding: 3rem 0 2rem;
      margin-top: 4rem;
    }
    
    .footer a {
      color: rgba(255, 255, 255, 0.8);
      transition: color 0.3s ease;
      text-decoration: none;
    }
    
    .footer a:hover {
      color: white;
    }
    
    .icon-link {
      margin: 0 0.5rem;
      font-size: 1.5rem;
    }


    /* Center all images by default with size constraints */
    img {
      display: block;
      margin: 0 auto;
      max-width: 600px; 
      height: auto;
    }


    .narrow-content {
      max-width: 600px;
      margin: 0 auto;
      padding: 0 1rem;
    }

    .extra-narrow-content {
      max-width: 500px;
      margin: 0 auto;
      padding: 0 1rem;
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarBasicExample">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div id="navbarBasicExample" class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://dongyuluo.github.io/">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
        <span>Home</span>
      </a>
    </div>
  </div>
</nav>

<!-- Hero Section with GIF Background -->
<section class="hero-section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered hero-content">
        <h1 class="publication-title fade-in">
          <span class="name">ControlTac</span>: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image
        </h1>

        <div class="is-size-5 publication-authors fade-in">
          <span class="author-block">
            <a href="https://dongyuluo.github.io/">Dongyu Luo*†</a>,</span>
          <span class="author-block">
            <a href="https://colinyu1.github.io/">Kelin Yu*</a>,</span>
          <span class="author-block">
            <a href="https://amirshahid.github.io/">Amir-Hossein Shahidzadeh</a>,
          </span>
          <br>
          <span class="author-block">
            <a href="https://users.umiacs.umd.edu/~fermulcm/">Cornelia Fermuler</a>,
          </span>
          <span class="author-block">
            <a href="https://robotics.umd.edu/clark/faculty/350/Yiannis-Aloimonos">Yiannis Aloimonos</a>,
          </span>
          <span class="author-block">
            <a href="https://ruohangao.github.io/">Ruohan Gao</a>
          </span>
        </div>

        <div class="is-size-5 publication-authors">
          <span class="author-block">University of Maryland</span>
        </div>
        <div class="is-size-6 has-text-centered" style="color: rgba(255, 255, 255, 0.8); margin-top: 0.5rem;">
          * Indicates equal contribution<br>
          †Dongyu is affiliated with The University of Hong Kong. The work was done during an internship at the University of Maryland.
        </div>


        <div class="publication-links fade-in">
          <span class="link-block">
            <a href="https://arxiv.org/pdf/2505.20498"
               class="external-link button is-normal is-rounded">
              <span class="icon">
                  <i class="fas fa-file-pdf"></i>
              </span>
              <span>Paper</span>
            </a>
          </span>
          <span class="link-block">
            <a href="https://arxiv.org/abs/2505.20498"
               class="external-link button is-normal is-rounded">
              <span class="icon">
                  <i class="ai ai-arxiv"></i>
              </span>
              <span>arXiv</span>
            </a>
          </span>
          <span class="link-block">
            <a class="external-link button is-normal is-rounded" disabled>
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code (Coming Soon)</span>
            </a>
          </span>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Video Section - Now at the top -->
<section class="video-hero fade-in">
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <div class="video-container">
        <iframe 
          src="https://www.youtube.com/embed/L6sNBcffjeU" 
          title="ControlTac Introduction Video"
          frameborder="0" 
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
          allowfullscreen>
        </iframe>
      </div>
    </div>
  </div>
</section>

<!-- Teaser Section -->
<section class="teaser-section fade-in">
  <div class="container is-max-desktop">
    <div class="teaser-content">
      <img src="./static/images/teaser.png" alt="ControlTac Teaser" class="teaser-image responsive-image" />
      <div class="teaser-description">
        <p>
          <strong>At a Glance:</strong> Starting from a single reference image, <span class="name" style="color: var(--primary-blue);">ControlTac</span> generates thousands of 
          augmented tactile images with controllable contact forces and positions <em>(Left)</em>. 
          These generated images prove highly effective for downstream tasks <em>(Middle)</em> and demonstrate practical utility 
          in real-world robotic experiments <em>(Right)</em>.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Abstract Section -->
<section class="abstract-section">
  <div class="content-wrapper">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="section-title">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision-based tactile sensing has been widely used in perception, reconstruction, 
            and robotic manipulation. However, collecting large-scale tactile data remains costly 
            due to the localized nature of sensor-object interactions and inconsistencies across 
            sensor instances. Existing approaches to scaling tactile data, such as simulation and
            free-form tactile generation, often suffer from unrealistic output and poor transferability 
            to downstream tasks.
          </p>
          <p>
            To address this, we propose <span class="name" style="color: var(--primary-blue);">ControlTac</span>, a 
            two-stage controllable framework that generates realistic tactile images conditioned on a 
            single reference tactile image, contact force, and contact position. With those physical 
            priors as control input, <span class="name" style="color: var(--primary-blue);">ControlTac</span> generates physically plausible 
            and varied tactile images that can be used for effective data augmentation. 
            Through experiments on three downstream tasks, we demonstrate that <span class="name" style="color: var(--primary-blue);">ControlTac</span> 
            can effectively augment tactile datasets and lead to consistent gains. 
            Our three real-world experiments further validate the practical utility of our approach.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Method Section -->
<section class="method-section">
  <div class="content-wrapper">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="section-title">Method Overview</h2>
        <div class="content has-text-justified">
          <p>
            <span class="name" style="color: var(--primary-blue);">ControlTac</span> consists of two key components:
            <strong>a. Force-Control:</strong> We input the background-removed tactile image <em>x</em> into the DiT model, conditioned on the 3D contact force <em>ΔF</em>, to generate force-specific tactile variations.
            <strong>b. Position-Control:</strong> We transfer the pretrained DiT from stage one and fine-tune it using ControlNet, conditioned on a contact mask <em>c</em>, to synthesize realistic tactile images <em>y<sub>B</sub></em> under different contact positions and forces.
          </p>
        </div>

        <div class="image-container">
          <img src="./static/images/framework.png" alt="ControlTac Framework" class="responsive-image">
        </div>
        
        <div class="content has-text-left" style="margin-top: 2rem;">
          <p>Here, we demonstrate how to annotate the contact mask to represent the contact position.</p>
          <div class="gif-container">
            <img src="./static/images/mask.gif" alt="Contact Mask Annotation" class="responsive-image" style="max-width: 80%;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Visualization Section -->
<section class="visualization-section">
  <div class="content-wrapper">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="section-title">Visualization</h2>

        <h3 class="subtitle is-5">Qualitative Comparison</h3>
        <div class="content has-text-justified">
          <p>
            We conduct a qualitative comparison between <span class="name" style="color: var(--primary-blue);">ControlTac</span> and other generators and simulators. <span class="name" style="color: var(--primary-blue);">ControlTac</span> exhibits superior realism, variation, and controllability in the generated tactile images.
          </p>
          <div class="image-container">
            <img src="./static/images/vis1.png" alt="Comparison with other methods" class="responsive-image">
          </div>
        </div>

        <h3 class="subtitle is-5">Comparison with Baseline Models</h3>
        <div class="content has-text-justified">
          <p>
            The first column displays 3D previews of six objects, followed by the input tactile image (Ref. Image) 
            in the second column and the Contact Mask in the third column. The fourth column shows the initial force 
            (top) and target force (bottom). Subsequent columns depict the Ground Truth (G.T.) and results from <span class="name" style="color: var(--primary-blue);">ControlTac</span>, 
            the hybrid force-position conditional diffusion model (Hybrid), and the separate-control pipeline (Separate). 
            In part A), we visualize the generated images for comparison; in part B), we visualize the 
            error maps highlighting the differences from the ground-truth tactile image.
          </p>
          <div class="image-container">
            <img src="./static/images/vis2.png" alt="Baseline comparison" class="responsive-image">
          </div>
        </div>

        <h3 class="subtitle is-5">Force-Controlled and Position-Controlled Generation</h3>
        <div class="content has-text-justified">
          <p>
            The figure below showcases the generation results of force-controlled and position-controlled components in <span class="name" style="color: var(--primary-blue);">ControlTac</span>.
          </p>
          <div class="gif-container">
            <img src="./static/images/vis3.gif" alt="Force and position control demonstration" class="responsive-image" style="max-width: 80%;">
          </div>
        </div>

        <h3 class="subtitle is-5">Diversity of Generated Tactile Images</h3>
        <div class="content has-text-justified">
          <p>
            The figure below clearly demonstrates that <span class="name" style="color: var(--primary-blue);">ControlTac</span> can generate a diverse range of tactile images from a single reference tactile image.
          </p>
          <div class="gif-container">
            <img src="./static/images/vis4_new.gif" alt="Diversity demonstration" class="responsive-image">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Downstream Tasks Section -->
<section class="downstream-section">
  <div class="content-wrapper">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="section-title">Downstream Tasks</h2>

        <h3 class="subtitle is-5">Force Estimation</h3>
        <div class="content has-text-justified">
          <p>
            The left figure illustrates how the force-controlled component in <span class="name" style="color: var(--primary-blue);">ControlTac</span> augments 
            1,000 real samples with a larger set of generated tactile images, leading to a substantial reduction in MAE 
            compared to using real data alone. Notably, by incorporating the generated data, the model achieves comparable 
            performance to training on the full real dataset (20,000 images) using only 8,000 real samples. This demonstrates 
            that the generated data effectively enrich the force distribution at each contact position, thereby enhancing the 
            training of the force estimator. Moreover, combining a larger quantity of both real and generated data yields the 
            best overall performance, underscoring the realism and utility of the generated samples.
          </p>
          <p>
            Building on the force-controlled component, we further integrate the position-controlled component of 
            <span class="name" style="color: var(--primary-blue);">ControlTac</span>. To highlight the importance of diverse contact positions in 
            training a robust force estimator, we divide the real dataset by contact angle, since tactile image 
            appearance varies across different contact angles. The right figure presents the MAE of force estimation 
            under different training conditions. The results show that incorporating position-controlled generation 
            effectively compensates for limited angular diversity in real data, significantly improving performance 
            even when only a small subset of real images is available—especially in scenarios where the real data covers 
            a narrow range of angles.
          </p>
          <div class="image-container">
            <img src="./static/images/force1.png" alt="Force estimation results" class="responsive-image">
          </div>
          <p>
            We further validate the effectiveness of <span class="name" style="color: var(--primary-blue);">ControlTac</span> in real-world pushing 
            experiments. The force estimator trained only with generated tactile data achieves
            comparable performance to the one trained on real tactile data, demonstrating that the generated data is 
            realistic and reliable enough to be used directly for training in practical scenarios.
          </p>
          <div class="gif-container">
            <img src="./static/images/force2.gif" alt="Real-world pushing experiments" class="responsive-image" style="max-width: 80%;">
          </div>
        </div>

        <h3 class="subtitle is-5">Position Estimation</h3>
        <div class="content has-text-justified">
          <p>
            As shown in the table below, pose estimators trained on tactile images generated by 
            <span class="name" style="color: var(--primary-blue);">ControlTac</span> achieve strong performance across all objects, 
            including the unseen T Shape. In particular, using a larger amount of generated data 
            leads to better results than using real data alone, as it is sufficiently realistic 
            and covers a much wider range of contact positions and forces. We also compare the 
            performance of the pose estimator using varying forces versus a fixed force (denoted 
            as fixed in the table below, where the fixed force is set to the median value of 6.5 N). 
            The results show that using varying force yields better performance, as contact force naturally 
            changes during inference.
          </p>
          <div class="image-container">
            <img src="./static/images/pos1.png" alt="Pose estimation comparison" class="responsive-image" style="max-width: 50%;">
          </div>
          <p>
            To further evaluate the performance of the pose estimator trained with <span class="name" style="color: var(--primary-blue);">ControlTac</span>-generated data, 
            we conducted a real-time pose tracking experiment. Our model successfully tracked poses at a 
            frequency of 10 Hz, highlighting its practicality in dynamic real-world scenarios.
          </p>
          <div class="gif-container">
            <img src="./static/images/tracking.gif" alt="Real-time pose tracking" class="responsive-image">
          </div>
          <p>
            In the Precise Insertion task, the pose estimator trained with <span class="name" style="color: var(--primary-blue);">ControlTac</span>-generated 
            data achieved success rates of 90% on the cylinder and 85% on the cross. Notably, 
            it also reached an 85% success rate on the unseen T-shape.
          </p>
          <div class="gif-container">
            <img src="./static/images/insertion.gif" alt="Precise insertion task results" class="responsive-image" style="max-width: 50%;">
          </div>
        </div>

        <h3 class="subtitle is-5">Object Classification</h3>
        <div class="content has-text-justified">
          <p>
            In the object classification task, we found that compared to traditional augmentation methods, using <span class="name" style="color: var(--primary-blue);">ControlTac</span> for data augmentation yields significantly better performance—whether with a simple CNN classifier, a ViT trained from scratch, or a ViT pretrained on ImageNet.
          </p>
          <p style="font-style: italic;">
            Note: G = geometric augmentation; C = color augmentation; Gen = our <span class="name" style="color: var(--primary-blue);">ControlTac</span>-based augmentation method.
          </p>
          <div class="image-container">
            <img src="./static/images/classification.png" alt="Object classification results" class="responsive-image">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- BibTeX Section -->
<section class="section" id="BibTeX">
  <div class="content-wrapper">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="section-title has-text-centered">BibTeX</h2>
        <pre><code>@article{luo2025controltac,
  title={ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image},
  author={Luo, Dongyu and Yu, Kelin and Shahidzadeh, Amir-Hossein and Fermuller, Cornelia and Aloimonos, Yiannis and Gao, Ruohan},
  journal={arXiv preprint arXiv:2505.20498},
  year={2025}
}</code></pre>
      </div>
    </div>
  </div>
</section>



<footer class="footer">
  <div class="container has-text-centered">
    <div class="content">
      <a class="icon-link" href="https://arxiv.org/pdf/2505.20498">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link external-link" href="https://github.com/DongyuLUO">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="content">
      <p style="margin-top: 1rem; font-style: italic; color: white;">
        Website template modified from
        <a href="https://nerfies.github.io/" target="_blank" rel="noopener noreferrer">NeRFies</a>
      </p>
    </div>
  </div>
</footer>


<script>
  // Navbar burger functionality for mobile
  document.addEventListener('DOMContentLoaded', () => {
    // Get all "navbar-burger" elements
    const navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);

    // Add a click event on each of them
    navbarBurgers.forEach(el => {
      el.addEventListener('click', () => {
        // Get the target from the "data-target" attribute
        const target = el.dataset.target;
        const targetElement = document.getElementById(target);

        // Toggle the "is-active" class on both the "navbar-burger" and the "navbar-menu"
        el.classList.toggle('is-active');
        targetElement.classList.toggle('is-active');
      });
    });
  });
</script>

</body>
</html>
